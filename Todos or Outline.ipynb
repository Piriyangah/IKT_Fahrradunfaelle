{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60156846-0e54-477a-9ec7-afcffec27853",
   "metadata": {},
   "source": [
    "## TO DO\n",
    "\n",
    "### Steps on how to tackle the project\n",
    "\n",
    "#### What is the Project?\n",
    "\n",
    "#### **Predict a bicycle accident.**\n",
    "\n",
    "\n",
    "- [x] **Understand the Datasets**\n",
    "- [ ] **Define the problem**\n",
    "   - Objective: Predict whether a given situation (defined by features such as time, location, weather, etc.) is likely to result in a bicycle accident.\n",
    "   - Output: A binary classification where 1 indicates a high likelihood of an accident and 0 indicates a low likelihood (which could include near misses or safe conditions).\n",
    "&nbsp;\n",
    "\n",
    "- [ ] **Data Preparation**\n",
    "   - Combine the Datasets: merge the datasets and add an extra column to indicate whether the incident was an accident (1) or near miss (0)\n",
    "     - the column could be called 'accident likelihood etc'\n",
    "     - **Maybe rename some columns** e.g\n",
    "       - **The i1 - i9 in near accidents could be renamed similarly to actual accidents. e.g i7 = ist PKW etc**\n",
    "     - **columns to maybe get rid of**\n",
    "         - Actual accidents: 'OBJECTID', 'LINREFX', 'LINREFY',\n",
    "         - Near accidents: 'desc'\n",
    "   - Handling Imbalance:\n",
    "        - If the datasets are imbalanced (more near misses than accidents),\n",
    "     consider using techniques like:\n",
    "        - Oversampling: Duplicate accident instances.\n",
    "        - Undersampling: Reduce the number of near-miss instances.\n",
    "        - Synthetic Data Generation: Use techniques like SMOTE to create synthetic samples of the minority class (accidents).\n",
    "   - Handle Missing Values:\n",
    "   - Data cleaning\n",
    "&nbsp;\n",
    "\n",
    "- [ ] **Feature Engineering**\n",
    "    - Time-Based Features: Extract new features from the time(e.g hour, day, month, holiday etc)\n",
    "       - [ ] **will need to do this for the bi-nearly accidents**\n",
    "         - **Currently, we have ts(timestamp) We will need to extract hour, day, month etc so that it could be uniform like actual accidents**\n",
    "\n",
    "     - Spatial Features: Convert locations to Coordinates or use Spatial clustering to identify high-risk zones\n",
    "        - [ ] **did something similar on merge file**\n",
    "          - **We converted lat and lon to distance and classified the near accidents that happened next to actual accidents.**\n",
    "          - **We also identified the locations with the most accidents**\n",
    "          - *Results are in the near accidents CSV file. see merge file for more info on function etc*\n",
    "\n",
    "    - Weather Features: Include detailed weather data such as precipitation, temperature, visibility, and wind speed.\n",
    "       - Actual accidents column: 'ULICHTVERH', 'IstStrassenzustand', \n",
    "       - Near accidents: no info on weather. However, after deducing the day and time from 'ts', we could match it to the weather in actual accidents.\n",
    "         \n",
    "    - Traffic and Road Features: Aggregate traffic volume data, road type, presence of bike lanes, speed limits, etc.\n",
    "       - Actual accidents: \n",
    "       - Near accidents:\n",
    "      \n",
    "    - Driver and Cyclist Behavior: Include features that might capture risky behaviours (speed, sudden stops, proximity to other vehicles).\n",
    "       - Actual accidents: \n",
    "       - Near accidents:\n",
    "         \n",
    "    - Interaction Features: Create interaction terms between relevant features (e.g., traffic volume during rush hour).\n",
    "\n",
    " &nbsp;\n",
    "- [ ] **Feature Selection**\n",
    "  - Correlation Analysis: Identify which features are most correlated with accidents and near misses.\n",
    "     - Actual accidents: istPKW, 'ULICHTVERH'= 0(daylight), 'IstStrassenzustand'= 0(dry)\n",
    "     - Near accidents: i7(car), i4(delivery/van)\n",
    "  - Feature Importance: Use techniques like random forest importance or LASSO to determine the most important features.\n",
    "  - Dimensionality Reduction: Consider PCA or other techniques if you have a large number of features.\n",
    "\n",
    "  - **Example Target Variable: 'Scary', , 'Accident Likelihood'(new column still to be created after combining the datasets etc**\n",
    "\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "- [ ] **Model Selection**\n",
    "- **Model Types**\n",
    "    - Logistic Regression: Simple and interpretable, useful as a baseline model.\n",
    "    - Random Forest/Gradient Boosting: These models handle non-linear relationships well and often perform strongly in classification tasks.\n",
    "    - Support Vector Machines (SVM): Effective in high-dimensional spaces and with clear margins of separation.\n",
    "    - Ensemble Methods: Combining several models (e.g., stacking or boosting) might improve prediction accuracy.\n",
    "    - Neural Networks: If the dataset is large and complex, neural networks might capture complex patterns. (This is disqualified. Too complex for the scope and we don't have too much data)\n",
    " \n",
    "&nbsp;\n",
    "\n",
    "- [ ] **Model Training**\n",
    "   - Split the Data: Divide the data into training, validation, and test sets (e.g., 70% training, 15% validation, 15% test).\n",
    "   - Cross-Validation: Use k-fold cross-validation to ensure the model generalizes well.\n",
    "   - Hyperparameter Tuning: Use Grid Search, Random Search, or Bayesian optimization to find the best hyperparameters.\n",
    "   - Class Imbalance Handling: If the dataset is imbalanced (e.g., more accidents than near misses), consider techniques like oversampling, undersampling, or using class weights.\n",
    "     \n",
    "&nbsp;\n",
    "    \n",
    "- [ ] **Model Evaluation**\n",
    "   - Performance Metrics: Use metrics like accuracy, precision, recall, F1-score, and ROC-AUC to evaluate the model’s performance.\n",
    "   - Confusion Matrix: Analyze the confusion matrix to understand where the model makes errors (e.g., false positives vs. false negatives).\n",
    "   - Precision-Recall Curve: Particularly useful when dealing with imbalanced datasets.\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "- [ ] **Model Interpretation and Testing**\n",
    "   - Feature Importance Analysis: Identify which features the model considers most important in distinguishing between accidents and near misses.\n",
    "   - Model Explanation: Use techniques like SHAP (SHapley Additive exPlanations) to understand how individual predictions are made.\n",
    "   - Testing on Unseen Data: Validate the model on a separate test set to ensure that it generalizes well to new data.\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "- [ ] **Deployment and Monitoring**\n",
    "   - Deploy the Model: If the model meets the performance criteria, deploy it in a real-world scenario where it can be used to predict the likelihood of an accident or near miss.\n",
    "   - Monitor Performance: Continuously monitor the model's performance over time and retrain it as new data becomes available.\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "- [ ] **Consider Ethical implications**\n",
    "   - Bias: Ensure the model doesn't inadvertently introduce or exacerbate biases (e.g., based on location or time).\n",
    "   - Transparency: Make the model interpretable to ensure stakeholders can understand and trust its predictions.\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "- [ ] **Real-Time Prediction (Optional)**\n",
    "  - Data Pipeline: If predicting accidents in real-time, set up a pipeline that ingests real-time data (e.g., weather, traffic) and feeds it to the model.\n",
    "  - Alerts: Implement a system that triggers alerts when the model predicts a high likelihood of an accident.\n",
    "\n",
    "\n",
    "This approach aims to create a robust model that can predict bicycle accidents based on historical data and patterns identified in both accident and near-miss incidents.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6853461-8c25-42ba-8a1c-5f09e7c2724e",
   "metadata": {},
   "source": [
    "#### Differentiate between actual accident and near miss\n",
    "- [ ] Understand the Datasets\n",
    "- [ ] Data Preparation\n",
    "   - Combine the Datasets: merge the datasets and add an extra column to indicate whether the incident was an accident (1) or near miss (0)\n",
    "   - Handle Missing Values:\n",
    "   - Data cleaning\n",
    "     \n",
    "- [ ] Feature Engineering\n",
    "    - Time-Based Features: Extract new features from the time(e.g hour, day, month, holiday etc)\n",
    "    - Spatial Features: Convert locations to Coordinates or use Spatial clustering to identify high-risk zones\n",
    "    - Interaction Terms: Create features that capture interactions between other features (e.g., the interaction between traffic volume and road type).\n",
    "    - Environmental Conditions: Enhance weather data by including features like visibility, temperature, and wind speed.\n",
    "    - Driver and Cyclist Behavior: If available, use data on speed, abrupt braking, or other behavioural indicators.\n",
    "      \n",
    "- [ ] Model Selection\n",
    "- Model Types\n",
    "    - Logistic Regression: Simple and interpretable, useful as a baseline model.\n",
    "    - Decision Trees/Random Forest: Good for handling non-linear relationships and interactions between features.\n",
    "    - Support Vector Machines (SVM): Effective in high-dimensional spaces and with clear margins of separation.\n",
    "    - Gradient Boosting Machines (XGBoost, LightGBM): Powerful for tabular data and often performs well in classification tasks.\n",
    "    - Neural Networks: If the dataset is large and complex, neural networks might capture complex patterns. (This is disqualified. Too complex for the scope and we don't have too much data)\n",
    "- [ ] Model Training\n",
    "   - Split the Data: Divide the data into training, validation, and test sets (e.g., 70% training, 15% validation, 15% test).\n",
    "   - Hyperparameter Tuning: Use techniques like Grid Search or Random Search combined with cross-validation on the training set to tune hyperparameters.\n",
    "   - Class Imbalance Handling: If the dataset is imbalanced (e.g., more accidents than near misses), consider techniques like oversampling, undersampling, or using class weights.\n",
    "- [ ] Model Evaluation\n",
    "   - Performance Metrics: Use metrics like accuracy, precision, recall, F1-score, and ROC-AUC to evaluate the model’s performance.\n",
    "   - Confusion Matrix: Analyze the confusion matrix to understand where the model makes errors (e.g., false positives vs. false negatives).\n",
    "   - Cross-Validation: Ensure robustness by performing k-fold cross-validation and evaluating the consistency of the results.\n",
    "- [ ] Model Interpretation and Testing\n",
    "   - Feature Importance Analysis: Identify which features the model considers most important in distinguishing between accidents and near misses.\n",
    "   - Model Explanation: Use techniques like SHAP (SHapley Additive exPlanations) to understand how individual predictions are made.\n",
    "   - Testing on Unseen Data: Validate the model on a separate test set to ensure that it generalizes well to new data.\n",
    "- [ ] Deployment and Monitoring\n",
    "   - Deploy the Model: If the model meets the performance criteria, deploy it in a real-world scenario where it can be used to predict the likelihood of an accident or near miss.\n",
    "   - Monitor Performance: Continuously monitor the model's performance over time and retrain it as new data becomes available.\n",
    "- [ ] Consider Ethical implications\n",
    "   - Bias and Fairness: Ensure that the model does not introduce or exacerbate biases, especially if the features used could unfairly impact certain groups (e.g., specific locations or times of day)\n",
    "   - Explainability: Make sure that the model's decisions can be explained to stakeholders, especially in safety-critical applications.\n",
    " \n",
    "\n",
    "This approach will help build a machine-learning model that can effectively differentiate between bicycle accidents and near misses, providing valuable insights for improving cyclist safety.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0d9053-9e55-421e-99b1-af0c977fd8c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
